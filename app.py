# app.py (Vers√£o Final com Agente Conversacional, Inten√ß√£o, Ferramentas e Guardrails)
import streamlit as st
import os
import smtplib
from email.message import EmailMessage
from urllib.parse import quote

import google.generativeai as genai
from dotenv import load_dotenv

# Imports para LangChain e Pydantic
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field

# --- CONFIGURA√á√ÉO INICIAL DA P√ÅGINA E VARI√ÅVEIS DE AMBIENTE ---
st.set_page_config(page_title="Assistente Agrofel", page_icon="üåø", layout="wide")

# L√≥gica para carregar a chave de API de forma segura
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except (FileNotFoundError, KeyError):
        st.error("Chave de API do Google n√£o encontrada! Configure-a no arquivo .env ou nos segredos do Streamlit.")
        st.stop()
genai.configure(api_key=api_key)


# --- DEFINI√á√ÉO DAS FERRAMENTAS PARA O AGENTE ---
class ResponderConversa(BaseModel):
    """Ferramenta para responder a sauda√ß√µes, despedidas ou conversas informais que n√£o s√£o perguntas t√©cnicas."""
    resposta_cordial: str = Field(description="Uma resposta curta, amig√°vel e profissional. Ex: 'Boa noite! Em que posso ajudar?'.")

class BuscaRecomendacao(BaseModel):
    """Ferramenta para buscar recomenda√ß√µes gerais de produtos para um problema agr√≠cola."""
    problema_agricola: str = Field(description="A descri√ß√£o do problema do utilizador, incluindo praga e cultura se mencionados. Ex: 'guanxuma na soja'.")

class BuscaTecnica(BaseModel):
    """Ferramenta para buscar uma resposta t√©cnica sobre um produto espec√≠fico."""
    nome_produto: str = Field(description="O nome do produto sobre o qual se pergunta, extra√≠do do hist√≥rico da conversa. Ex: 'GLYPHOTAL TR'.")
    pergunta_tecnica: str = Field(description="A pergunta t√©cnica espec√≠fica. Ex: 'qual a dosagem para 1 hectare?'.")


# --- FUN√á√ïES DE L√ìGICA (BACKEND DA APLICA√á√ÉO) ---

@st.cache_resource(show_spinner="A carregar base de conhecimento...")
def carregar_base_conhecimento():
    """ Carrega o √≠ndice FAISS pr√©-constru√≠do do reposit√≥rio. """
    CAMINHO_INDEX_FAISS = "faiss_index_agrofel"
    if not os.path.exists(CAMINHO_INDEX_FAISS):
        st.error(f"ERRO CR√çTICO: A base de conhecimento ('{CAMINHO_INDEX_FAISS}') n√£o foi encontrada.")
        return None, None
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        db = FAISS.load_local(CAMINHO_INDEX_FAISS, embeddings, allow_dangerous_deserialization=True)
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro-latest", temperature=0.2)
        return db, llm
    except Exception as e:
        st.error(f"Ocorreu um erro ao carregar a base de conhecimento: {e}")
        return None, None

def _run_rag_chain(query: str, db, llm, prompt_template: str):
    """ Fun√ß√£o gen√©rica para executar uma cadeia RAG. """
    docs = db.similarity_search(query, k=5)
    if not docs:
        return "Com base nas informa√ß√µes dispon√≠veis, n√£o encontrei uma resposta espec√≠fica na nossa base de dados. Poderia reformular a sua pergunta?"
    
    contexto = "\n\n---\n\n".join([doc.page_content for doc in docs])
    prompt = ChatPromptTemplate.from_template(prompt_template)
    cadeia = prompt | llm | StrOutputParser()
    return cadeia.invoke({"contexto": contexto, "pergunta": query})

def ferramenta_buscar_recomendacao(problema_agricola: str, db, llm):
    """ Ferramenta que busca recomenda√ß√µes de produtos. """
    prompt_template = """
Voc√™ √© um consultor especialista da Agrofel. Sua tarefa √© gerar uma recomenda√ß√£o de produtos com base na pergunta do cliente e nas informa√ß√µes das bulas.
Seja cordial e profissional.

PERGUNTA DO CLIENTE: "{pergunta}"

INFORMA√á√ïES RELEVANTES DAS BULAS:
---
{contexto}
---

INSTRU√á√ïES:
1. Com base **estritamente** nas informa√ß√µes fornecidas, sugira at√© DOIS produtos relevantes.
2. Para cada produto, extraia o NOME EXATO e crie uma descri√ß√£o curta e convincente.
3. Formato da Resposta:
   **Produto 1:** [Nome do Produto]
   **Descri√ß√£o:** [Sua descri√ß√£o]

   **Produto 2:** [Nome do Produto]
   **Descri√ß√£o:** [Sua descri√ß√£o]
4. Se as informa√ß√µes n√£o forem suficientes para uma recomenda√ß√£o segura, responda APENAS com: "Com base nas informa√ß√µes dispon√≠veis, n√£o encontrei um produto espec√≠fico para a sua solicita√ß√£o. Poderia reformular a sua pergunta ou gostaria de falar com um especialista?"
5. NUNCA invente nomes de produtos ou informa√ß√µes t√©cnicas.
"""
    return _run_rag_chain(problema_agricola, db, llm, prompt_template)

def ferramenta_buscar_resposta_tecnica(nome_produto: str, pergunta_tecnica: str, db, llm):
    """ Ferramenta que busca respostas t√©cnicas sobre um produto. """
    query = f"informa√ß√µes sobre {nome_produto} para responder: {pergunta_tecnica}"
    prompt_template = """
Voc√™ √© um assistente t√©cnico da Agrofel. Sua tarefa √© responder a uma pergunta t√©cnica sobre um produto, baseando-se **exclusivamente** nas informa√ß√µes das bulas.
Seja preciso e cordial.

PRODUTO: "{pergunta}"
INFORMA√á√ïES RELEVANTES DAS BULAS:
---
{contexto}
---

INSTRU√á√ïES:
1. Responda √† pergunta do utilizador de forma clara e direta, usando apenas os dados fornecidos.
2. Se a informa√ß√£o exata n√£o estiver nos trechos, responda: "N√£o encontrei esta informa√ß√£o espec√≠fica na bula do produto. Para detalhes t√©cnicos, recomendo consultar um engenheiro agr√¥nomo ou falar com um de nossos especialistas."
3. NUNCA invente valores, dosagens ou especifica√ß√µes.
"""
    return _run_rag_chain(query, db, llm, prompt_template)

def orquestrador_conversacional(query: str, chat_history: list, db, llm):
    """
    O c√©rebro do agente. Analisa a inten√ß√£o e chama a ferramenta correta.
    """
    historico_formatado = "\n".join([f"{msg['role']}: {msg['content']}" for msg in chat_history])
    
    prompt_roteador = f"""
Voc√™ √© o orquestrador de um chatbot de agronomia. Sua tarefa √© analisar a √öLTIMA PERGUNTA DO UTILIZADOR e o HIST√ìRICO DA CONVERSA para decidir qual ferramenta chamar. Seja cordial e profissional.

- Se a pergunta for uma sauda√ß√£o, despedida ou conversa informal (ex: 'Ol√°', 'Boa noite', 'Obrigado', 'Quem √© voc√™?'), use a ferramenta `ResponderConversa`.
- Se a pergunta for geral, sobre um problema agr√≠cola (ex: 'praga na soja', 'o que usar para guanxuma'), use a ferramenta `BuscaRecomendacao`.
- Se a pergunta for claramente sobre um produto espec√≠fico j√° mencionado no hist√≥rico (ex: 'qual a dosagem desse produto?', 'como aplicar o Glyphotal?'), use a ferramenta `BuscaTecnica`.

HIST√ìRICO DA CONVERSA:
{historico_formatado}

√öLTIMA PERGUNTA DO UTILIZADOR: {query}
"""
    
    llm_com_ferramentas = llm.bind_tools([BuscaRecomendacao, BuscaTecnica, ResponderConversa])
    analise = llm_com_ferramentas.invoke(prompt_roteador)

    if not analise.tool_calls:
        return "Pe√ßo desculpa, n√£o consegui entender a sua pergunta. Poderia tentar reformul√°-la de outra maneira?"
    
    ferramenta_chamada = analise.tool_calls[0]
    nome_ferramenta = ferramenta_chamada['name']
    argumentos = ferramenta_chamada['args']

    if nome_ferramenta == ResponderConversa.__name__:
        return argumentos.get("resposta_cordial", "Ol√°! Como posso ajudar?")

    if nome_ferramenta == BuscaTecnica.__name__:
        return ferramenta_buscar_resposta_tecnica(
            nome_produto=argumentos.get("nome_produto"),
            pergunta_tecnica=argumentos.get("pergunta_tecnica"),
            db=db,
            llm=llm
        )
    
    return ferramenta_buscar_recomendacao(
        problema_agricola=argumentos.get("problema_agricola", query),
        db=db,
        llm=llm
    )

# --- Guardrail de Seguran√ßa de Entrada ---
def is_input_safe(query: str) -> bool:
    """ Verifica se a entrada do utilizador cont√©m linguagem inadequada. """
    # Esta √© uma lista de exemplo. Pode ser expandida com mais termos.
    blocklist = ["palavr√£o", "insulto", "ofensa", "agress√£o"]
    query_lower = query.lower()
    if any(word in query_lower for word in blocklist):
        return False
    return True

# --- Fun√ß√µes de Notifica√ß√£o (sem altera√ß√µes) ---
def enviar_email_confirmacao(pergunta, recomendacao):
    # ... (c√≥digo de envio de email aqui)
    pass

def gerar_link_whatsapp(pergunta, recomendacao):
    # ... (c√≥digo do link WhatsApp aqui)
    pass

# --- INTERFACE DO USU√ÅRIO (CHAT) ---
st.title("üåø Assistente de Campo Agrofel")
st.markdown("---")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Ol√°! Sou o assistente virtual da Agrofel. Como posso ajudar com a sua lavoura hoje?"}]

db, llm = carregar_base_conhecimento()

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # Adicionar bot√µes de a√ß√£o √†s mensagens do assistente que cont√™m recomenda√ß√µes
        if message["role"] == "assistant" and "Produto 1:" in message["content"]:
            st.markdown("---")
            # ... (L√≥gica dos bot√µes de a√ß√£o pode ser adicionada aqui se desejado)

if prompt := st.chat_input("Descreva o seu problema ou fa√ßa uma pergunta..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # --- Execu√ß√£o com Guardrail ---
    if not is_input_safe(prompt):
        response = "Pe√ßo desculpa, mas n√£o posso processar pedidos com linguagem inadequada. Por favor, mantenha a conversa profissional e focada em quest√µes agr√≠colas."
    elif db is not None and llm is not None:
        with st.chat_message("assistant"):
            with st.spinner("A pensar..."):
                historico_para_analise = st.session_state.messages[:-1]
                response = orquestrador_conversacional(prompt, historico_para_analise, db, llm)
                st.markdown(response)
    else:
        response = "N√£o foi poss√≠vel conectar √† base de conhecimento. Por favor, recarregue a p√°gina."
    
    st.session_state.messages.append({"role": "assistant", "content": response})
