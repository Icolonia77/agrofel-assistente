# app.py (Vers√£o Final com Transforma√ß√£o de Consulta)
import streamlit as st
import os
import google.generativeai as genai
from dotenv import load_dotenv

# Imports para LangChain
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# --- CONFIGURA√á√ÉO INICIAL DA P√ÅGINA E VARI√ÅVEIS DE AMBIENTE ---
st.set_page_config(page_title="Assistente Agrofel", page_icon="üåø", layout="wide")

# L√≥gica para carregar a chave de API de forma segura
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except (FileNotFoundError, KeyError):
        st.error("Chave de API do Google n√£o encontrada! Configure-a no arquivo .env ou nos segredos do Streamlit.")
        st.stop()
genai.configure(api_key=api_key)


# --- FUN√á√ïES DE L√ìGICA (BACKEND DA APLICA√á√ÉO) ---

@st.cache_resource(show_spinner="A carregar base de conhecimento...")
def carregar_base_conhecimento():
    """
    Carrega o √≠ndice FAISS pr√©-constru√≠do do reposit√≥rio.
    """
    CAMINHO_INDEX_FAISS = "faiss_index_agrofel"
    if not os.path.exists(CAMINHO_INDEX_FAISS):
        st.error(f"ERRO CR√çTICO: A base de conhecimento pr√©-constru√≠da ('{CAMINHO_INDEX_FAISS}') n√£o foi encontrada.")
        return None, None
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        db = FAISS.load_local(CAMINHO_INDEX_FAISS, embeddings, allow_dangerous_deserialization=True)
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro-latest", temperature=0.3)
        return db, llm
    except Exception as e:
        st.error(f"Ocorreu um erro ao carregar a base de conhecimento: {e}")
        return None, None

def agente_especialista_recomenda(query: str, db, llm):
    """
    Implementa a l√≥gica RAG com Transforma√ß√£o de Consulta para maior robustez.
    """
    if db is None or llm is None:
        return "Erro: A base de conhecimento n√£o est√° carregada."

    # ETAPA 1: TRANSFORMA√á√ÉO DA CONSULTA
    # Usamos um LLM para gerar m√∫ltiplas consultas de busca a partir da pergunta original.
    template_transformacao = """Voc√™ √© um especialista em agronomia. Sua tarefa √© transformar a pergunta de um utilizador numa lista de 3 consultas de busca otimizadas para uma base de dados vetorial.
    As consultas devem ser concisas e variadas para cobrir diferentes aspetos da pergunta.
    Responda apenas com as consultas, uma por linha.

    Pergunta Original: {pergunta}

    Consultas de Busca:
    """
    prompt_transformacao = ChatPromptTemplate.from_template(template_transformacao)
    
    cadeia_transformacao = prompt_transformacao | llm | StrOutputParser()
    consultas_geradas = cadeia_transformacao.invoke({"pergunta": query}).strip().split('\n')

    st.sidebar.subheader("Consultas de Busca Geradas")
    st.sidebar.write(consultas_geradas)

    # ETAPA 2: BUSCA AUMENTADA
    # Fazemos uma busca para cada consulta gerada e juntamos os resultados.
    todos_chunks = []
    for consulta in consultas_geradas:
        todos_chunks.extend(db.similarity_search(consulta, k=3))
    
    # Removemos duplicados, se houver
    unique_chunks = {doc.page_content: doc for doc in todos_chunks}.values()

    if not unique_chunks:
        return "NAO_ENCONTRADO"

    contexto_final = "\n\n---\n\n".join([doc.page_content for doc in unique_chunks])

    # ETAPA 3: GERA√á√ÉO DA RESPOSTA FINAL
    # A l√≥gica de gera√ß√£o permanece a mesma, mas agora com um contexto muito melhor.
    prompt_geracao_final = f"""Voc√™ √© um consultor especialista da Agrofel. Com base nos TRECHOS RELEVANTES DAS BULAS, gere uma recomenda√ß√£o clara e objetiva.

    PERGUNTA ORIGINAL DO AGRICULTOR: "{query}"

    TRECHOS RELEVANTES DAS BULAS (obtidos de m√∫ltiplas buscas):
    ---
    {contexto_final}
    ---
    INSTRU√á√ïES:
    1. Sugira at√© DOIS produtos que melhor respondam √† pergunta. Se encontrar apenas um, sugira apenas um.
    2. Extraia o nome exato do produto e crie uma descri√ß√£o curta e convincente.
    3. Formato:
       **Produto 1:** [Nome do Produto]
       **Descri√ß√£o:** [Sua descri√ß√£o]

       **Produto 2:** [Nome do Produto]
       **Descri√ß√£o:** [Sua descri√ß√£o]
    4. Se os trechos n√£o forem suficientes, responda APENAS com: "NAO_ENCONTRADO".
    """
    resposta_final = llm.invoke(prompt_geracao_final)
    return resposta_final.content

# --- INTERFACE DO USU√ÅRIO ---
st.title("üåø Assistente de Campo Agrofel")
with st.sidebar:
    st.header("Op√ß√µes de Desenvolvedor")
    if st.button("üö® Limpar Cache da Aplica√ß√£o"):
        st.cache_resource.clear()
        st.success("Cache limpo! A aplica√ß√£o ir√° recarregar a base de dados.")
        st.rerun()

st.markdown("Bem-vindo! Descreva seu problema com pragas na lavoura e encontrarei a melhor solu√ß√£o para voc√™.")

db, llm = carregar_base_conhecimento()

if 'recomendacao' not in st.session_state: st.session_state.recomendacao = ""
if 'pergunta' not in st.session_state: st.session_state.pergunta = ""

with st.form("pergunta_form"):
    pergunta_usuario = st.text_area("Qual praga est√° afetando sua lavoura e em qual cultura?", height=100, placeholder="Ex: Capim amargoso na soja")
    submitted = st.form_submit_button("Buscar Sugest√µes")

if submitted and pergunta_usuario:
    if db is not None:
        with st.spinner("Analisando as melhores solu√ß√µes para voc√™..."):
            st.session_state.pergunta = pergunta_usuario
            recomendacao_gerada = agente_especialista_recomenda(pergunta_usuario, db, llm)
            st.session_state.recomendacao = recomendacao_gerada
    else:
        st.error("A base de conhecimento n√£o p√¥de ser carregada.")

if st.session_state.recomendacao:
    if "NAO_ENCONTRADO" in st.session_state.recomendacao:
        st.warning("N√£o encontrei produtos espec√≠ficos para sua solicita√ß√£o em nossa base de dados.")
    else:
        st.subheader("Encontrei estas sugest√µes para voc√™:")
        st.markdown(st.session_state.recomendacao)
    
    # L√≥gica dos bot√µes de a√ß√£o (simplificada para clareza)
    st.markdown("---")
    st.markdown("O que voc√™ gostaria de fazer?")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("‚úÖ Confirmar Pedido", type="primary", use_container_width=True):
            st.success("Pedido confirmado! Seu consultor Agrofel foi notificado.")
            st.balloons()
            st.session_state.recomendacao = ""
    with col2:
        if st.button("üó£Ô∏è Falar com um Humano", use_container_width=True):
            st.info("Sua solicita√ß√£o foi registrada. Um especialista entrar√° em contato.")
            st.session_state.recomendacao = ""

